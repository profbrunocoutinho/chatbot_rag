# ü¶ô Chatbot RAG com LLaMA (Execu√ß√£o Local)

Este projeto √© um chatbot orquestrador do tipo **RAG (Retrieval-Augmented Generation)** utilizando o modelo **LLaMA ou Mistral quantizado (.gguf)** para execu√ß√£o local com `llama-cpp-python`.

O chatbot permite consultas sem√¢nticas a documentos PDF indexados via FAISS, com interface web desenvolvida em **Streamlit**.

---

## ‚úÖ Tecnologias Utilizadas

- Python 3.10+
- Streamlit
- LangChain
- FAISS (persist√™ncia vetorial)
- Hugging Face Embeddings (`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`)
- `llama-cpp-python` (modelo local quantizado)
- Modelos suportados: LLaMA, Mistral ou compat√≠veis no formato `.gguf`

---

## ‚öôÔ∏è Pr√©-Requisitos

- Python 3.10 ou superior instalado
- Compilador C/C++ configurado (Visual Studio Build Tools no Windows)
- CMake instalado
- `llama-cpp-python` corretamente instalado (compilado)
- Arquivo `.gguf` do modelo LLaMA ou Mistral baixado
- Base FAISS previamente criada com os documentos PDF

---

## üöÄ Instala√ß√£o

### 1. Clone o reposit√≥rio
```bash
git clone https://github.com/seu-usuario/chatbot-rag-llama.git
cd chatbot-rag-llama

